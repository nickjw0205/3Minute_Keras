{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dZWiu7hzXsD3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os.path \n",
    "import numpy as np \n",
    "from keras.models import * \n",
    "from keras.layers import * \n",
    "from keras.optimizers import * \n",
    "import keras.backend as K \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H90dpFGZX8Y7"
   },
   "outputs": [],
   "source": [
    "K.set_image_data_format('channels_last')\n",
    "class Gan:\n",
    "  def __init__(self, img_data): \n",
    "    img_size = img_data.shape[1] \n",
    "    channel = img_data.shape[3] if len(img_data.shape) >= 4 else 1 \n",
    "    \n",
    "    self.img_data = img_data \n",
    "    self.input_shape = (img_size, img_size, channel) \n",
    "    self.img_rows = img_size \n",
    "    self.img_cols = img_size \n",
    "    self.channel = channel \n",
    "    self.noise_size = 100 \n",
    "    \n",
    "    # Create D and G. \n",
    "    self.create_d() \n",
    "    self.create_g() \n",
    "    \n",
    "    # Build model to train D. \n",
    "    optimizer = Adam(lr=0.0008) \n",
    "    self.D.compile(loss='binary_crossentropy', optimizer=optimizer) \n",
    "    \n",
    "    # Build model to train G. \n",
    "    optimizer = Adam(lr=0.0004) \n",
    "    self.D.trainable = False \n",
    "    self.AM = Sequential() \n",
    "    self.AM.add(self.G) \n",
    "    self.AM.add(self.D) \n",
    "    self.AM.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SQh1zXgzYU6e"
   },
   "outputs": [],
   "source": [
    "def create_d(self): \n",
    "  self.D = Sequential() \n",
    "  depth = 64 \n",
    "  dropout = 0.4 \n",
    "  self.D.add(Conv2D(depth*1, 5, strides=2, input_shape=self.input_shape, padding='same')) \n",
    "  self.D.add(LeakyReLU(alpha=0.2)) \n",
    "  self.D.add(Dropout(dropout)) \n",
    "  self.D.add(Conv2D(depth*2, 5, strides=2, padding='same')) \n",
    "  self.D.add(LeakyReLU(alpha=0.2)) \n",
    "  self.D.add(Dropout(dropout)) \n",
    "  self.D.add(Conv2D(depth*4, 5, strides=2, padding='same')) \n",
    "  self.D.add(LeakyReLU(alpha=0.2)) \n",
    "  self.D.add(Dropout(dropout)) \n",
    "  self.D.add(Conv2D(depth*8, 5, strides=1, padding='same')) \n",
    "  self.D.add(LeakyReLU(alpha=0.2)) \n",
    "  self.D.add(Dropout(dropout)) \n",
    "  self.D.add(Flatten()) \n",
    "  self.D.add(Dense(1)) \n",
    "  self.D.add(Activation('sigmoid')) \n",
    "  self.D.summary() \n",
    "  return self.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rqHGjhSHYoZU"
   },
   "outputs": [],
   "source": [
    "def create_g(self): \n",
    "  self.G = Sequential() \n",
    "  dropout = 0.4 \n",
    "  depth = 64+64+64+64 \n",
    "  dim = 8 \n",
    "  self.G.add(Dense(dim*dim*depth, input_dim=self.noise_size)) \n",
    "  self.G.add(BatchNormalization(momentum=0.9)) \n",
    "  self.G.add(Activation('relu')) \n",
    "  self.G.add(Reshape((dim, dim, depth))) \n",
    "  self.G.add(Dropout(dropout)) \n",
    "  self.G.add(UpSampling2D()) \n",
    "  self.G.add(Conv2DTranspose(int(depth/2), 5, padding='same')) \n",
    "  self.G.add(BatchNormalization(momentum=0.9)) \n",
    "  self.G.add(Activation('relu')) \n",
    "  self.G.add(UpSampling2D()) \n",
    "  self.G.add(Conv2DTranspose(int(depth/4), 5, padding='same')) \n",
    "  self.G.add(BatchNormalization(momentum=0.9)) \n",
    "  self.G.add(Activation('relu')) \n",
    "  self.G.add(Conv2DTranspose(int(depth/8), 5, padding='same')) \n",
    "  self.G.add(BatchNormalization(momentum=0.9)) \n",
    "  self.G.add(Activation('relu')) \n",
    "  self.G.add(Conv2DTranspose(self.channel, 5, padding='same')) \n",
    "  self.G.add(Activation('sigmoid')) \n",
    "  self.G.summary() \n",
    "  return self.G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8d7U-5RkZINi"
   },
   "outputs": [],
   "source": [
    "def train(self, batch_size=100): \n",
    "\n",
    "  # Pick image data randomly. \n",
    "  images_train = self.img_data[np.random.randint(0, self.img_data.shape[0], size=batch_size), :, :, :] \n",
    "  \n",
    "  # Generate images from noise. \n",
    "  noise = np.random.uniform(-1.0, 1.0, size=[batch_size, self.noise_size]) \n",
    "  images_fake = self.G.predict(noise) \n",
    "  \n",
    "  # Train D. \n",
    "  x = np.concatenate((images_train, images_fake)) \n",
    "  y = np.ones([2*batch_size, 1]) \n",
    "  y[batch_size:, :] = 0 \n",
    "  self.D.trainable = True \n",
    "  d_loss = self.D.train_on_batch(x, y) \n",
    "  \n",
    "  # Train G. \n",
    "  y = np.ones([batch_size, 1]) \n",
    "  noise = np.random.uniform(-1.0, 1.0, size=[batch_size, self.noise_size]) \n",
    "  self.D.trainable = False \n",
    "  a_loss = self.AM.train_on_batch(noise, y) \n",
    "  \n",
    "  return d_loss, a_loss, images_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_UjLeiYSZaKj"
   },
   "outputs": [],
   "source": [
    "def save(self): \n",
    "  self.G.save_weights('gan_g_weights.h5') \n",
    "  self.D.save_weights('gan_d_weights.h5') \n",
    "\n",
    "def load(self): \n",
    "  if os.path.isfile('gan_g_weights.h5'): \n",
    "    self.G.load_weights('gan_g_weights.h5') \n",
    "    print(\"Load G from file.\") \n",
    "    if os.path.isfile('gan_d_weights.h5'): \n",
    "      self.D.load_weights('gan_d_weights.h5') \n",
    "      print(\"Load D from file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RwTCQ3BsZhVs"
   },
   "outputs": [],
   "source": [
    "class PokemonData(): \n",
    "  def __init__(self): \n",
    "    img_data_list = [] \n",
    "    images = os.listdir(\"pokemon_jpg\") \n",
    "    for path in images: \n",
    "      img = image.open(r\"C:\\Users\\USER\\Documents\\holy\\3Minute_Keras\\Unit_7\\pokemon_jpg\") \n",
    "      img_data_list.append([np.array(img).astype('float32')]) \n",
    "      \n",
    "    self.x_train = np.vstack(img_data_list) / 255.0 \n",
    "    print(self.x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "id": "ylfsm3TrZvE8",
    "outputId": "bd938a96-5115-453f-fcc9-8bc31baa771e"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3ae11cc1e181>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load dataset.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPokemonData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Init network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-6d3364c2329e>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pokemon_jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m       \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\USER\\Documents\\holy\\3Minute_Keras\\Unit_7\\pokemon_jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m       \u001b[0mimg_data_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image' is not defined"
     ]
    }
   ],
   "source": [
    "# Load dataset. \n",
    "dataset = PokemonData() \n",
    "x_train = dataset.x_train \n",
    "\n",
    "# Init network \n",
    "gan = Gan(x_train) \n",
    "gan.load() \n",
    "\n",
    "# Some parameters. \n",
    "epochs = 500 \n",
    "sample_size = 10 \n",
    "batch_size = 100 \n",
    "train_per_epoch = x_train.shape[0] // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "TqdhTfXhZ6JT",
    "outputId": "fdee4da5-483a-4629-f4a6-176418765705"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-616664a46ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mtotal_d_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mtotal_a_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, epochs): \n",
    "  total_d_loss = 0.0 \n",
    "  total_a_loss = 0.0 \n",
    "  imgs = None \n",
    "  for batch in range(0, train_per_epoch): \n",
    "    d_loss, a_loss, t_imgs = gan.train(batch_size) \n",
    "    total_d_loss += d_loss \n",
    "    total_a_loss += a_loss \n",
    "    if imgs is None: \n",
    "      imgs = t_imgs \n",
    "      \n",
    "    if epoch % 20 == 0 or epoch == epochs - 1: \n",
    "      total_d_loss /= train_per_epoch \n",
    "      total_a_loss /= train_per_epoch \n",
    "    \n",
    "    print(\"Epoch: {}, D Loss: {}, AM Loss: {}\" .format(epoch, total_d_loss, total_a_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "IT2nJbp7aNxL",
    "outputId": "b5fcb52e-64ed-4885-8f5b-c730eb6e947d"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-00957552115c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Show generated images.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis_off\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0max\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_size' is not defined"
     ]
    }
   ],
   "source": [
    "# Show generated images. \n",
    "fig, ax = plt.subplots(1, sample_size, figsize=(sample_size, 1)) \n",
    "for i in range(0, sample_size): \n",
    "  ax[i].set_axis_off() \n",
    "  ax[i].imshow(imgs[i].reshape((gan.img_rows, gan.img_cols, gan.channel)), interpolation='nearest'); \n",
    "  \n",
    "plt.show() \n",
    "plt.close(fig); \n",
    "\n",
    "# Save weights \n",
    "gan.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBL2zAb1adGI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DCGAN_POK.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
